# -*- coding: utf-8 -*-
"""Data pre-processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p48oRd5Hbn2byAXHjhD1nn-OeAnFFSfD
"""

#%reload_ext tensorboard
import tensorflow as tf 
import datetime
import pandas as pd
from pandas import ExcelWriter
from pandas import ExcelFile 
import numpy as np 
from tensorflow import keras 
from sklearn.preprocessing import MinMaxScaler 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM 
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
import matplotlib.pyplot as plt
import math

#!rm -rf ./logs/ #resets the item

#sep = pd.read_csv('WC September 2019 Hourly.csv')
#sep.columns = ["Netowrk_ID","VDS_number","Date", " Hour", "Class", "Count", "Average_Speed"]
sep_sorted= pd.read_csv('September_2019_pending.csv' )
#sep_sorted

#sep_sorted = sep_sorted.columns = ["VDS_number","Date", " Hour", "Class", "Count", "Sum_Total"]
sep_sorted.rename(columns={"ID":"VDS","Date ":"Date","Unnamed: 2":"Hour","Unnamed: 3":"Class","Unnamed: 4":"Count","Unnamed: 5":"Sum_Total"})

#sep.drop(['Netowrk_ID','Average_Speed'], axis = 1, inplace = True)
sep_sorted['Date '] = sep_sorted['Date '].str.replace('00:00:00.0000000', '')

#sep_sorted.head()

#dff = sep_sorted.groupby(["ID", 'Hour']).Count.sum().reset_index()
#dff
#This is the sum of all the counts at a point for the month 
#i.e sum of all dates at specific hour at a specific point

num_ix = sep_sorted['ID'].str.extract('(\d+)') #This isolates the number within the ID  feild

sep_sorted['ID_num'] = num_ix
#sep_sorted.head()

new_sorted = sep_sorted.groupby(["ID_num", 'Hour','Date ']).Count.sum().reset_index() #This is the final sort

new_sorted.sort_values(['Date ','ID_num'],inplace = True )
#new_sorted.head()
#Organised mainly organised mainly as the column

check  = new_sorted.groupby('ID_num').size()

#Use to check the number of counts for a particlar point 
ix_102 = new_sorted['ID_num'].str.contains('314')
id_102 = new_sorted[ix_102]

check_102 = id_102.groupby('Hour').size()
check_102



#95% of values are present. Max value is 720 
 #30 (days) * 24( 0 to 23 hours recorded) = 720 
check_ix = abs(check)>648
check_id = check[check_ix]

id = list(check_id.index)
id

#if new_sorted['ID_num'] in id: 
#fin_ix = new_sorted['ID_num']
#fin_sort = new_sorted[fin_ix]

fin_sort = new_sorted[new_sorted['ID_num'].isin(id)]

fin_sort.shape

#Implement where you can add values and it makes predictions