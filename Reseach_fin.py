# -*- coding: utf-8 -*-
"""Thesis_Fin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16l7KdQ_9moZHIrTmimaMtlJoJp0bKC9W
"""

import tensorflow as tf 
import pandas as pd
from pandas import ExcelWriter
from pandas import ExcelFile 
import numpy as np 
from tensorflow import keras 
from sklearn.preprocessing import MinMaxScaler 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM , GRU
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

data= pd.read_csv('Combined_109.csv' )

target = data[['Count']]
training_data = target.values

#scaling data 
scaler = MinMaxScaler(feature_range=(0,1))
scaler.fit(training_data)
scaled_data = scaler.transform(training_data)

train_len= int(len(scaled_data) * 0.8)
train_len

#Creating the training dataset 
split_data = scaled_data[0:train_len]
x_train = []
y_train = []
time_step = 100 #This is 24*7, to symbolise a week of date being used as the tim step 
for i in range(time_step ,len(split_data)): 
  x_train.append(split_data[i-time_step:i,0]) #The first 24 values go into 
  y_train.append(split_data[i,0])

x_train = np.array(x_train) #convert the iteger into an array
y_train = np.array(y_train)
x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))

#build the model
model = Sequential()
model.add(LSTM(48, input_shape = (x_train.shape[1],1), return_sequences=True, name="Input_layer")) # (Timestep, dimensition)
model.add(LSTM(24,activation='relu', return_sequences=True, name = 'Hidden_layer_1'))
model.add(LSTM(24, name = 'Hidden_layer_2'))
model.add(keras.layers.Dropout(0.2, name = 'Dropout'))
model.add(Dense(1, name= 'Output_layer'))
model.compile(optimizer = 'RMSprop', loss = 'mae' , metrics=['accuracy']) #adam, mse

model.fit(x_train ,y_train, batch_size=20 , epochs= 100, verbose = 1)

model.save('LSTM4_e100_b20_v2.h5')

model.summary()

test_data = scaled_data[:-train_len]
test_data = np.array(test_data)
test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1],1))
true_test = target[:-train_len]
true_train = target[:train_len]

test_data = scaled_data[train_len-time_step:,:] #(train_data length - 24 )
x_test = []
y_test = target[:-train_len]
for i in range(time_step,len(test_data)):
  x_test.append(test_data[i-time_step:i,0])

x_test =np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1)) #make it 3d

x_test.shape

predictions = model.predict(x_test) #scaled
predictions = scaler.inverse_transform(predictions) #coverting from scaled to unscaled 
true_test = y_test 
error =  true_test - predictions
#Getting the error
print("Root mean Squared")
rmse = np.sqrt(np.mean(error)**2)
print('{}'.format(rmse))

print('Mean Absolue  Error')
MAE = np.mean(np.abs(error))
print('{}'.format(MAE))

print('Mean Absolue Percentage Error')
MAPE = np.mean(np.abs((error)/true_test)) * 100
print('{}%'.format(MAPE))

val_data = scaled_data
val_data = np.array(val_data)
val_data.shape

new_output =[]
i = 0 # needed
#test data should be np.array(sscaled_data)
np_list = val_data  # taking the testing data in the shape [2000,1,1]
while i<350:
  y_input = np.reshape(np_list,(1,np_list.shape[0],1)) # Reshape t allow for one output
  y_out = model.predict(y_input, verbose=0) # predict 
  y_np = np.array(y_out) #Convert the sinle output to numpy array
  np_list = np.append(np_list , y_np) # Add it to the end of the list 
  new_output.extend(y_out.tolist()) # Add the output to a list 
  i=i+1 #This should go until all predicted days are accouned fo

test_pred_ls= scaler.inverse_transform(new_output)
#checkix = 0.15 * test_pred 
#check = test_pred - checkix
#plt.plot(check)
plt.plot(test_pred)

march_109 = pd.read_csv('March_109.csv')

march_count = march_109[['Count']]

plt.figure(figsize=(16,8))
plt.title('Model Forcast')
plt.xlabel('Index of Time Series')
plt.ylabel('Traffic Volume')
#plt.plot( range(len(test_pred[:168])),test_pred[:168], label = 'GRU Model Prediction')
plt.plot( range(len(test_pred_ls[:168])),test_pred_ls[:168], label = 'LSTM Model Prediction')
#plt.plot( range(len(old_test_pred[:168])),old_test_pred[:168], label = 'Old predictions')
plt.plot( range(len(march_count[:168])),march_count[:168], label = 'Actual Recorded Values')
#plt.xlabel()
plt.legend()
#It it close for 60 hours

#predictions = model.predict(x_test) #scaled
#predictions = scaler.inverse_transform(predictions) #coverting from scaled to unscaled 
predictions = test_pred[:168]
true_test = march_count[:168] 
error =  true_test - predictions
#Getting the error
print("Root mean Squared")
rmse = np.sqrt(np.mean(error)**2)
print('{}'.format(rmse))

print('Mean Absolue  Error')
MAE = np.mean(np.abs(error))
print('{}'.format(MAE))

print('Mean Absolue Percentage Error')
MAPE = np.mean(np.abs((error)/true_test)) * 100
print('{}%'.format(MAPE))

predictions_train = model.predict(x_test) #scaled
predictions_train = scaler.inverse_transform(predictions_train)

#true_test = target[:-train_len]
#true_train = target[:train_len]
valid = target[:-train_len]
valid['Predictions'] = predictions_train

true_train.shape

old = np.arange(1,50)
new = np.arange(50,218)
plt.figure(figsize=(16,8))
plt.title('Model Training')
plt.xlabel('Index of Time Series')
plt.ylabel('Traffic Volumes')
plt.plot(old,true_train['Count'][:-3423])
plt.plot(new, valid[['Count','Predictions']][:168])                
plt.legend(['Training Data', 'Test Data', 'Predictions'])
plt.show()

target.shape

march_for = march_count[:350]
march_for['Forcast'] = test_pred

old = np.arange(1,48)
new = np.arange(48,216)
plt.figure(figsize=(16,8))
plt.title('Model Forcast')
plt.xlabel('Index of Time Series')
plt.ylabel('Traffic Volume')
plt.plot(old,target['Count'][:-4294])
plt.plot(new, march_for[['Count','Forcast']][:168])                
plt.legend(['Febuary', 'March', 'Model Forcast'])
plt.show()

fin_for = march_count[:350]
fin_for['GRU_Forcast'] = gru_for
fin_for['LSTM_Forcast'] = lstm_for

old = np.arange(1,48)
new = np.arange(48,216)
plt.figure(figsize=(16,8))
plt.title('Model Forcast Comparison')
plt.xlabel('Index of Time Series')
plt.ylabel('Traffic Volume')
plt.plot(old,target['Count'][:-4294])
plt.plot(new, fin_for[['Count','GRU_Forcast','LSTM_Forcast']][:168])                
plt.legend(['Febuary', 'March', 'GRU Forcast', 'LSTM Forcast'])
plt.show()

